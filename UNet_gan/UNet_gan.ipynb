{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89378f69-bc06-4ed8-8a0c-706ec0f2c04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import config.unetConfig as cfg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from data import BraTSDataset\n",
    "from UNet_trainer import GANTrainer\n",
    "from UNet_generator import UNetGenerator\n",
    "from UNet_encoder_decoder import UNetDiscriminator\n",
    "from IPython.display import HTML\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import weights_init_norm, weights_init_ortho, plot_train_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa16066-4f63-4797-98cc-a6bb95f03d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset preprocessing from the 77th slice \n",
    "class BraTSDataset(Dataset):\n",
    "    def __init__(self, image_paths, transforms=None) -> None:\n",
    "        # Filter out non-existent or empty files\n",
    "        valid_paths = []\n",
    "        for path in image_paths:\n",
    "            if os.path.exists(path) and os.path.getsize(path) > 0:\n",
    "                valid_paths.append(path)\n",
    "            else:\n",
    "                print(f\"[Warning] Skipping invalid or missing file: {path}\")\n",
    "\n",
    "        if len(valid_paths) == 0:\n",
    "            raise ValueError(\"No valid image files found!\")\n",
    "\n",
    "        self.imagePaths = valid_paths\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imagePaths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        imagePath = self.imagePaths[index]\n",
    "        try:\n",
    "            nii_image = nib.load(imagePath)\n",
    "            image = nii_image.get_fdata()[:, :, 77]\n",
    "            image = np.uint8(image / image.max() * 255)\n",
    "            image = Image.fromarray(image)\n",
    "\n",
    "            if self.transforms is not None:\n",
    "                image = self.transforms(image)\n",
    "\n",
    "            return image\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] Failed to load or process: {imagePath}\\n{e}\")\n",
    "            # Optionally: Return a blank image or raise the error\n",
    "            raise e\n",
    "\n",
    "    def save(self, store_path):\n",
    "        os.makedirs(store_path, exist_ok=True)\n",
    "\n",
    "        for i, impath in enumerate(self.imagePaths):\n",
    "            try:\n",
    "                nii_image = nib.load(impath)\n",
    "                image = nii_image.get_fdata()[:, :, 77]\n",
    "                image = np.uint8(image / image.max() * 255)\n",
    "                image = Image.fromarray(image)\n",
    "\n",
    "                if self.transforms is not None:\n",
    "                    image = self.transforms(image)\n",
    "\n",
    "                vutils.save_image(image, f'{store_path}/{i}.png')\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Skipped saving image {i} ({impath}) due to error:\\n{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ce1940-3e79-478c-8df1-c4ed51d425e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "dpath = cfg.DSET_CPATHS[f\"{cfg.BT_CLASS}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b88c3e-83f8-4f15-9ad0-73282fb5ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the T1 image filepaths in a sorted manner\n",
    "image_paths = [os.path.join(dpath, impath) for impath in sorted(os.listdir(dpath))]\n",
    "\n",
    "tf = transforms.Compose([\n",
    "    transforms.Resize((cfg.INPUT_IMAGE_HEIGHT,cfg.INPUT_IMAGE_WIDTH)),\n",
    "    transforms.CenterCrop((cfg.INPUT_IMAGE_HEIGHT,cfg.INPUT_IMAGE_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "# Create the dataset\n",
    "dataset = BraTSDataset(image_paths, tf)\n",
    "\n",
    "# Create the dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=cfg.BATCH_SIZE,\n",
    "                        shuffle=True, num_workers=cfg.NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35181d51-21e7-4004-b515-1cfb088b05a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Training Images ({cfg.BT_CLASS})\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch.to(cfg.DEVICE), normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Create the generator\n",
    "netG = UNetGenerator(cfg.LATENT_SZ, cfg.NGF, cfg.NGC).to(cfg.DEVICE)\n",
    "\n",
    "# Apply the weights_init_ortho\n",
    "netG.apply(weights_init_norm)\n",
    "\n",
    "# Print the model\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbb282c-7e2b-4e2f-8d33-1eff755ae811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Discriminator\n",
    "netD = UNetDiscriminator(ns=cfg.NEG_SLOPE).to(cfg.DEVICE)\n",
    "\n",
    "# Apply the weights_init_ortho\n",
    "netD.apply(weights_init_ortho)\n",
    "\n",
    "# Print the model\n",
    "print(netD)\n",
    "trainer = GANTrainer(num_epochs=cfg.NUM_EPOCHS,\n",
    "                        glr=cfg.GLR, dlr=cfg.DLR,\n",
    "                        gbeta1=cfg.GBETA1, dbeta1=cfg.DBETA1,\n",
    "                        dataloader=dataloader,\n",
    "                        netG=netG, netD=netD,\n",
    "                        device=cfg.DEVICE)\n",
    "trainer.train(nz=cfg.LATENT_SZ, batch_sz=cfg.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914962ca-88b0-4ec7-b01c-6e4eb46e4803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4040414-ca3d-4105-80af-c1135f509e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b68d143-fb72-4944-9576-4909e6d6cd81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edea24ab-eb4c-4a23-8d04-448833ff6eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1515d4d0-9a06-4be4-8e36-897e1d7889f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588e67e6-1419-4839-b494-545d37914681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2c8371-82f7-42d5-b4aa-0fb28c1f43c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9688fd9b-6e1a-46a4-aab5-8314e1ab18ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
